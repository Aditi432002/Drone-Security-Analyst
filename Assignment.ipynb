{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpKY5mVsqQiO",
        "outputId": "7d2d997a-d9c0-4bf9-f942-81ff1fde5c2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.99-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Collecting ffmpeg-python\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.14.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python) (1.0.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.99-py3-none-any.whl (976 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m976.9/976.9 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ffmpeg-python, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed ffmpeg-python-0.2.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.99 ultralytics-thop-2.0.14\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics opencv-python pandas ffmpeg-python\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "video_path = \"/content/drone_footage.mp4\"\n",
        "\n",
        "if os.path.exists(video_path):\n",
        "    print(\"✅ Video file exists!\")\n",
        "else:\n",
        "    print(\"❌ Video file is missing! Please upload it.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iitw5fDCqTij",
        "outputId": "d2c10895-389b-4bd4-db9a-9188f9421b14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Video file exists!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Extracting Frames from Video\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "output_folder = \"/content/extracted_frames\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "print(f\"✅ FPS: {fps}, Total Frames: {total_frames}\")\n",
        "\n",
        "frame_number = 0\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    frame_path = os.path.join(output_folder, f\"frame_{frame_number:04d}.jpg\")\n",
        "    cv2.imwrite(frame_path, frame)\n",
        "    frame_number += 1\n",
        "\n",
        "cap.release()\n",
        "print(\"✅ Frames extracted successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGAKoO0Sqzc9",
        "outputId": "281b0252-76cb-4ce2-8a09-4dacd8503099"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ FPS: 23.976023976023978, Total Frames: 642\n",
            "✅ Frames extracted successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Running Object Detection on Extracted Frames\n",
        "from ultralytics import YOLO\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Load YOLOv8 model\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "detection_results = []\n",
        "frame_files = sorted(os.listdir(\"/content/extracted_frames\"))\n",
        "\n",
        "for frame_file in frame_files:\n",
        "    frame_path = os.path.join(\"/content/extracted_frames\", frame_file)\n",
        "    results = model(frame_path)  # Run YOLOv8 on the frame\n",
        "\n",
        "    for result in results:\n",
        "        df = result.to_df()  # Use `.to_df()` instead of `.pandas().xyxy[0]`\n",
        "        df[\"frame\"] = frame_file  # Add frame name\n",
        "        detection_results.append(df)\n",
        "\n",
        "# Save detection results to CSV\n",
        "df_all = pd.concat(detection_results, ignore_index=True)\n",
        "df_all.to_csv(\"/content/detection_results.csv\", index=False)\n",
        "\n",
        "print(\"✅ Object detection completed and saved!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yg5t4uSxq1d7",
        "outputId": "754844eb-cde2-4563-fa52-5a71ab39b4cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/extracted_frames/frame_0000.jpg: 352x640 3 persons, 133.6ms\n",
            "Speed: 2.7ms preprocess, 133.6ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0001.jpg: 352x640 3 persons, 127.1ms\n",
            "Speed: 2.7ms preprocess, 127.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0002.jpg: 352x640 3 persons, 124.1ms\n",
            "Speed: 2.8ms preprocess, 124.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0003.jpg: 352x640 3 persons, 126.3ms\n",
            "Speed: 2.7ms preprocess, 126.3ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0004.jpg: 352x640 3 persons, 134.6ms\n",
            "Speed: 3.9ms preprocess, 134.6ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0005.jpg: 352x640 3 persons, 131.8ms\n",
            "Speed: 3.3ms preprocess, 131.8ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0006.jpg: 352x640 3 persons, 126.3ms\n",
            "Speed: 2.8ms preprocess, 126.3ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0007.jpg: 352x640 3 persons, 126.5ms\n",
            "Speed: 2.9ms preprocess, 126.5ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0008.jpg: 352x640 3 persons, 123.4ms\n",
            "Speed: 3.1ms preprocess, 123.4ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0009.jpg: 352x640 3 persons, 135.8ms\n",
            "Speed: 3.2ms preprocess, 135.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0010.jpg: 352x640 3 persons, 132.2ms\n",
            "Speed: 2.9ms preprocess, 132.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0011.jpg: 352x640 3 persons, 125.9ms\n",
            "Speed: 2.7ms preprocess, 125.9ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0012.jpg: 352x640 3 persons, 126.8ms\n",
            "Speed: 2.8ms preprocess, 126.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0013.jpg: 352x640 2 persons, 124.0ms\n",
            "Speed: 2.7ms preprocess, 124.0ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0014.jpg: 352x640 3 persons, 132.1ms\n",
            "Speed: 2.8ms preprocess, 132.1ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0015.jpg: 352x640 3 persons, 138.8ms\n",
            "Speed: 4.0ms preprocess, 138.8ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0016.jpg: 352x640 3 persons, 126.5ms\n",
            "Speed: 2.7ms preprocess, 126.5ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0017.jpg: 352x640 3 persons, 128.8ms\n",
            "Speed: 2.8ms preprocess, 128.8ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0018.jpg: 352x640 3 persons, 124.4ms\n",
            "Speed: 2.8ms preprocess, 124.4ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0019.jpg: 352x640 3 persons, 126.1ms\n",
            "Speed: 2.7ms preprocess, 126.1ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0020.jpg: 352x640 3 persons, 137.6ms\n",
            "Speed: 2.9ms preprocess, 137.6ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0021.jpg: 352x640 3 persons, 135.8ms\n",
            "Speed: 3.1ms preprocess, 135.8ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0022.jpg: 352x640 3 persons, 125.8ms\n",
            "Speed: 2.9ms preprocess, 125.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0023.jpg: 352x640 3 persons, 125.9ms\n",
            "Speed: 2.8ms preprocess, 125.9ms inference, 2.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0024.jpg: 352x640 3 persons, 127.2ms\n",
            "Speed: 3.0ms preprocess, 127.2ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0025.jpg: 352x640 2 persons, 129.7ms\n",
            "Speed: 2.8ms preprocess, 129.7ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0026.jpg: 352x640 2 persons, 399.9ms\n",
            "Speed: 4.1ms preprocess, 399.9ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0027.jpg: 352x640 2 persons, 126.0ms\n",
            "Speed: 2.8ms preprocess, 126.0ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0028.jpg: 352x640 2 persons, 126.8ms\n",
            "Speed: 2.9ms preprocess, 126.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0029.jpg: 352x640 2 persons, 126.7ms\n",
            "Speed: 2.9ms preprocess, 126.7ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0030.jpg: 352x640 2 persons, 147.7ms\n",
            "Speed: 2.9ms preprocess, 147.7ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0031.jpg: 352x640 3 persons, 124.0ms\n",
            "Speed: 2.9ms preprocess, 124.0ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0032.jpg: 352x640 2 persons, 126.8ms\n",
            "Speed: 2.8ms preprocess, 126.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0033.jpg: 352x640 3 persons, 129.8ms\n",
            "Speed: 2.8ms preprocess, 129.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0034.jpg: 352x640 3 persons, 126.3ms\n",
            "Speed: 2.8ms preprocess, 126.3ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0035.jpg: 352x640 3 persons, 144.5ms\n",
            "Speed: 2.8ms preprocess, 144.5ms inference, 1.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0036.jpg: 352x640 3 persons, 125.9ms\n",
            "Speed: 2.8ms preprocess, 125.9ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0037.jpg: 352x640 3 persons, 129.1ms\n",
            "Speed: 2.8ms preprocess, 129.1ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0038.jpg: 352x640 3 persons, 127.3ms\n",
            "Speed: 2.8ms preprocess, 127.3ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0039.jpg: 352x640 3 persons, 125.8ms\n",
            "Speed: 2.7ms preprocess, 125.8ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0040.jpg: 352x640 3 persons, 128.2ms\n",
            "Speed: 2.8ms preprocess, 128.2ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0041.jpg: 352x640 3 persons, 141.6ms\n",
            "Speed: 3.8ms preprocess, 141.6ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0042.jpg: 352x640 3 persons, 128.2ms\n",
            "Speed: 2.9ms preprocess, 128.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0043.jpg: 352x640 3 persons, 124.5ms\n",
            "Speed: 2.9ms preprocess, 124.5ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0044.jpg: 352x640 3 persons, 128.4ms\n",
            "Speed: 2.8ms preprocess, 128.4ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0045.jpg: 352x640 2 persons, 127.8ms\n",
            "Speed: 2.9ms preprocess, 127.8ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0046.jpg: 352x640 2 persons, 149.9ms\n",
            "Speed: 3.2ms preprocess, 149.9ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0047.jpg: 352x640 2 persons, 124.4ms\n",
            "Speed: 2.8ms preprocess, 124.4ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0048.jpg: 352x640 2 persons, 128.3ms\n",
            "Speed: 2.8ms preprocess, 128.3ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0049.jpg: 352x640 2 persons, 180.4ms\n",
            "Speed: 2.8ms preprocess, 180.4ms inference, 2.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0050.jpg: 352x640 2 persons, 201.5ms\n",
            "Speed: 4.0ms preprocess, 201.5ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0051.jpg: 352x640 2 persons, 213.1ms\n",
            "Speed: 3.9ms preprocess, 213.1ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0052.jpg: 352x640 2 persons, 198.5ms\n",
            "Speed: 4.1ms preprocess, 198.5ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0053.jpg: 352x640 2 persons, 198.3ms\n",
            "Speed: 4.0ms preprocess, 198.3ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0054.jpg: 352x640 2 persons, 199.6ms\n",
            "Speed: 4.1ms preprocess, 199.6ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0055.jpg: 352x640 2 persons, 200.8ms\n",
            "Speed: 4.1ms preprocess, 200.8ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0056.jpg: 352x640 2 persons, 200.2ms\n",
            "Speed: 4.5ms preprocess, 200.2ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0057.jpg: 352x640 2 persons, 203.8ms\n",
            "Speed: 4.8ms preprocess, 203.8ms inference, 1.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0058.jpg: 352x640 3 persons, 208.2ms\n",
            "Speed: 4.1ms preprocess, 208.2ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0059.jpg: 352x640 3 persons, 130.5ms\n",
            "Speed: 3.9ms preprocess, 130.5ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0060.jpg: 352x640 3 persons, 128.0ms\n",
            "Speed: 2.8ms preprocess, 128.0ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0061.jpg: 352x640 3 persons, 123.7ms\n",
            "Speed: 2.8ms preprocess, 123.7ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0062.jpg: 352x640 3 persons, 132.3ms\n",
            "Speed: 3.4ms preprocess, 132.3ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0063.jpg: 352x640 3 persons, 126.4ms\n",
            "Speed: 2.8ms preprocess, 126.4ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0064.jpg: 352x640 3 persons, 138.6ms\n",
            "Speed: 4.2ms preprocess, 138.6ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0065.jpg: 352x640 3 persons, 287.3ms\n",
            "Speed: 2.8ms preprocess, 287.3ms inference, 3.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0066.jpg: 352x640 2 persons, 132.7ms\n",
            "Speed: 2.8ms preprocess, 132.7ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0067.jpg: 352x640 3 persons, 127.8ms\n",
            "Speed: 4.1ms preprocess, 127.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0068.jpg: 352x640 3 persons, 190.4ms\n",
            "Speed: 2.8ms preprocess, 190.4ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0069.jpg: 352x640 3 persons, 147.3ms\n",
            "Speed: 7.4ms preprocess, 147.3ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0070.jpg: 352x640 3 persons, 124.5ms\n",
            "Speed: 3.0ms preprocess, 124.5ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0071.jpg: 352x640 3 persons, 130.7ms\n",
            "Speed: 2.8ms preprocess, 130.7ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0072.jpg: 352x640 2 persons, 129.4ms\n",
            "Speed: 2.8ms preprocess, 129.4ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0073.jpg: 352x640 2 persons, 137.9ms\n",
            "Speed: 3.9ms preprocess, 137.9ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0074.jpg: 352x640 3 persons, 133.7ms\n",
            "Speed: 2.8ms preprocess, 133.7ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0075.jpg: 352x640 2 persons, 127.2ms\n",
            "Speed: 3.0ms preprocess, 127.2ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0076.jpg: 352x640 3 persons, 140.3ms\n",
            "Speed: 2.9ms preprocess, 140.3ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0077.jpg: 352x640 3 persons, 127.0ms\n",
            "Speed: 2.9ms preprocess, 127.0ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0078.jpg: 352x640 3 persons, 230.5ms\n",
            "Speed: 3.9ms preprocess, 230.5ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0079.jpg: 352x640 3 persons, 125.3ms\n",
            "Speed: 2.7ms preprocess, 125.3ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0080.jpg: 352x640 3 persons, 134.9ms\n",
            "Speed: 4.0ms preprocess, 134.9ms inference, 2.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0081.jpg: 352x640 3 persons, 186.8ms\n",
            "Speed: 3.3ms preprocess, 186.8ms inference, 2.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0082.jpg: 352x640 3 persons, 150.3ms\n",
            "Speed: 4.0ms preprocess, 150.3ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0083.jpg: 352x640 3 persons, 125.0ms\n",
            "Speed: 3.0ms preprocess, 125.0ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0084.jpg: 352x640 3 persons, 130.1ms\n",
            "Speed: 2.9ms preprocess, 130.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0085.jpg: 352x640 3 persons, 136.0ms\n",
            "Speed: 2.9ms preprocess, 136.0ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0086.jpg: 352x640 3 persons, 127.6ms\n",
            "Speed: 2.8ms preprocess, 127.6ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0087.jpg: 352x640 3 persons, 126.2ms\n",
            "Speed: 2.8ms preprocess, 126.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0088.jpg: 352x640 3 persons, 137.9ms\n",
            "Speed: 3.4ms preprocess, 137.9ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0089.jpg: 352x640 3 persons, 128.9ms\n",
            "Speed: 3.5ms preprocess, 128.9ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0090.jpg: 352x640 3 persons, 131.2ms\n",
            "Speed: 2.9ms preprocess, 131.2ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0091.jpg: 352x640 3 persons, 384.6ms\n",
            "Speed: 4.5ms preprocess, 384.6ms inference, 1.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0092.jpg: 352x640 2 persons, 125.8ms\n",
            "Speed: 2.8ms preprocess, 125.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0093.jpg: 352x640 2 persons, 125.7ms\n",
            "Speed: 2.8ms preprocess, 125.7ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0094.jpg: 352x640 3 persons, 131.2ms\n",
            "Speed: 2.8ms preprocess, 131.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0095.jpg: 352x640 3 persons, 124.1ms\n",
            "Speed: 3.0ms preprocess, 124.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0096.jpg: 352x640 3 persons, 129.9ms\n",
            "Speed: 2.8ms preprocess, 129.9ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0097.jpg: 352x640 3 persons, 134.9ms\n",
            "Speed: 2.8ms preprocess, 134.9ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0098.jpg: 352x640 3 persons, 128.0ms\n",
            "Speed: 3.0ms preprocess, 128.0ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0099.jpg: 352x640 2 persons, 134.7ms\n",
            "Speed: 2.8ms preprocess, 134.7ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0100.jpg: 352x640 2 persons, 127.0ms\n",
            "Speed: 2.9ms preprocess, 127.0ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0101.jpg: 352x640 2 persons, 130.4ms\n",
            "Speed: 3.0ms preprocess, 130.4ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0102.jpg: 352x640 3 persons, 128.1ms\n",
            "Speed: 2.8ms preprocess, 128.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0103.jpg: 352x640 3 persons, 128.1ms\n",
            "Speed: 2.7ms preprocess, 128.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0104.jpg: 352x640 3 persons, 129.7ms\n",
            "Speed: 2.9ms preprocess, 129.7ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0105.jpg: 352x640 3 persons, 129.4ms\n",
            "Speed: 3.2ms preprocess, 129.4ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0106.jpg: 352x640 3 persons, 128.3ms\n",
            "Speed: 2.9ms preprocess, 128.3ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0107.jpg: 352x640 3 persons, 198.1ms\n",
            "Speed: 2.9ms preprocess, 198.1ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0108.jpg: 352x640 3 persons, 204.5ms\n",
            "Speed: 4.0ms preprocess, 204.5ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0109.jpg: 352x640 3 persons, 197.8ms\n",
            "Speed: 4.2ms preprocess, 197.8ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0110.jpg: 352x640 3 persons, 195.1ms\n",
            "Speed: 4.1ms preprocess, 195.1ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0111.jpg: 352x640 3 persons, 199.7ms\n",
            "Speed: 4.0ms preprocess, 199.7ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0112.jpg: 352x640 3 persons, 200.8ms\n",
            "Speed: 4.3ms preprocess, 200.8ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0113.jpg: 352x640 3 persons, 202.5ms\n",
            "Speed: 4.3ms preprocess, 202.5ms inference, 1.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0114.jpg: 352x640 3 persons, 199.4ms\n",
            "Speed: 4.0ms preprocess, 199.4ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0115.jpg: 352x640 3 persons, 213.0ms\n",
            "Speed: 3.9ms preprocess, 213.0ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0116.jpg: 352x640 3 persons, 214.8ms\n",
            "Speed: 4.2ms preprocess, 214.8ms inference, 1.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0117.jpg: 352x640 3 persons, 126.3ms\n",
            "Speed: 2.8ms preprocess, 126.3ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0118.jpg: 352x640 3 persons, 130.3ms\n",
            "Speed: 2.8ms preprocess, 130.3ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0119.jpg: 352x640 3 persons, 169.3ms\n",
            "Speed: 2.9ms preprocess, 169.3ms inference, 33.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0120.jpg: 352x640 3 persons, 149.5ms\n",
            "Speed: 3.3ms preprocess, 149.5ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0121.jpg: 352x640 3 persons, 124.3ms\n",
            "Speed: 2.8ms preprocess, 124.3ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0122.jpg: 352x640 3 persons, 128.8ms\n",
            "Speed: 2.8ms preprocess, 128.8ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0123.jpg: 352x640 3 persons, 131.6ms\n",
            "Speed: 2.9ms preprocess, 131.6ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0124.jpg: 352x640 3 persons, 138.1ms\n",
            "Speed: 2.9ms preprocess, 138.1ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0125.jpg: 352x640 3 persons, 145.6ms\n",
            "Speed: 2.9ms preprocess, 145.6ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0126.jpg: 352x640 3 persons, 129.3ms\n",
            "Speed: 3.1ms preprocess, 129.3ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0127.jpg: 352x640 3 persons, 125.8ms\n",
            "Speed: 2.8ms preprocess, 125.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0128.jpg: 352x640 3 persons, 122.7ms\n",
            "Speed: 3.5ms preprocess, 122.7ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0129.jpg: 352x640 3 persons, 148.0ms\n",
            "Speed: 3.0ms preprocess, 148.0ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0130.jpg: 352x640 3 persons, 149.6ms\n",
            "Speed: 4.0ms preprocess, 149.6ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0131.jpg: 352x640 3 persons, 125.8ms\n",
            "Speed: 2.8ms preprocess, 125.8ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0132.jpg: 352x640 3 persons, 128.2ms\n",
            "Speed: 3.0ms preprocess, 128.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0133.jpg: 352x640 3 persons, 126.9ms\n",
            "Speed: 3.0ms preprocess, 126.9ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0134.jpg: 352x640 3 persons, 124.1ms\n",
            "Speed: 2.8ms preprocess, 124.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0135.jpg: 352x640 3 persons, 138.3ms\n",
            "Speed: 2.9ms preprocess, 138.3ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0136.jpg: 352x640 3 persons, 127.4ms\n",
            "Speed: 3.2ms preprocess, 127.4ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0137.jpg: 352x640 3 persons, 124.5ms\n",
            "Speed: 2.8ms preprocess, 124.5ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0138.jpg: 352x640 3 persons, 129.2ms\n",
            "Speed: 3.0ms preprocess, 129.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0139.jpg: 352x640 3 persons, 123.9ms\n",
            "Speed: 2.8ms preprocess, 123.9ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0140.jpg: 352x640 3 persons, 123.9ms\n",
            "Speed: 2.9ms preprocess, 123.9ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0141.jpg: 352x640 3 persons, 136.8ms\n",
            "Speed: 3.9ms preprocess, 136.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0142.jpg: 352x640 3 persons, 124.2ms\n",
            "Speed: 2.9ms preprocess, 124.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0143.jpg: 352x640 3 persons, 125.6ms\n",
            "Speed: 3.0ms preprocess, 125.6ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0144.jpg: 352x640 3 persons, 123.0ms\n",
            "Speed: 2.8ms preprocess, 123.0ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0145.jpg: 352x640 2 persons, 126.2ms\n",
            "Speed: 2.9ms preprocess, 126.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0146.jpg: 352x640 2 persons, 146.1ms\n",
            "Speed: 2.7ms preprocess, 146.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0147.jpg: 352x640 2 persons, 122.7ms\n",
            "Speed: 2.8ms preprocess, 122.7ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0148.jpg: 352x640 3 persons, 124.4ms\n",
            "Speed: 2.9ms preprocess, 124.4ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0149.jpg: 352x640 2 persons, 127.9ms\n",
            "Speed: 2.8ms preprocess, 127.9ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0150.jpg: 352x640 2 persons, 127.7ms\n",
            "Speed: 4.6ms preprocess, 127.7ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0151.jpg: 352x640 3 persons, 126.2ms\n",
            "Speed: 2.9ms preprocess, 126.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0152.jpg: 352x640 3 persons, 142.1ms\n",
            "Speed: 3.2ms preprocess, 142.1ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0153.jpg: 352x640 3 persons, 125.0ms\n",
            "Speed: 2.7ms preprocess, 125.0ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0154.jpg: 352x640 3 persons, 130.4ms\n",
            "Speed: 2.9ms preprocess, 130.4ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0155.jpg: 352x640 3 persons, 124.3ms\n",
            "Speed: 2.8ms preprocess, 124.3ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0156.jpg: 352x640 3 persons, 126.1ms\n",
            "Speed: 3.0ms preprocess, 126.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0157.jpg: 352x640 3 persons, 144.6ms\n",
            "Speed: 3.7ms preprocess, 144.6ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0158.jpg: 352x640 3 persons, 125.6ms\n",
            "Speed: 2.9ms preprocess, 125.6ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0159.jpg: 352x640 3 persons, 128.3ms\n",
            "Speed: 2.9ms preprocess, 128.3ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0160.jpg: 352x640 3 persons, 127.3ms\n",
            "Speed: 2.7ms preprocess, 127.3ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0161.jpg: 352x640 3 persons, 129.3ms\n",
            "Speed: 2.7ms preprocess, 129.3ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0162.jpg: 352x640 3 persons, 137.3ms\n",
            "Speed: 3.0ms preprocess, 137.3ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0163.jpg: 352x640 3 persons, 137.2ms\n",
            "Speed: 3.1ms preprocess, 137.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0164.jpg: 352x640 3 persons, 126.0ms\n",
            "Speed: 2.8ms preprocess, 126.0ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0165.jpg: 352x640 3 persons, 129.0ms\n",
            "Speed: 3.0ms preprocess, 129.0ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0166.jpg: 352x640 3 persons, 125.2ms\n",
            "Speed: 2.7ms preprocess, 125.2ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0167.jpg: 352x640 3 persons, 124.9ms\n",
            "Speed: 2.8ms preprocess, 124.9ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0168.jpg: 352x640 3 persons, 142.5ms\n",
            "Speed: 3.4ms preprocess, 142.5ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0169.jpg: 352x640 3 persons, 186.3ms\n",
            "Speed: 2.7ms preprocess, 186.3ms inference, 1.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0170.jpg: 352x640 3 persons, 203.5ms\n",
            "Speed: 4.0ms preprocess, 203.5ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0171.jpg: 352x640 3 persons, 195.3ms\n",
            "Speed: 4.2ms preprocess, 195.3ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0172.jpg: 352x640 3 persons, 200.0ms\n",
            "Speed: 4.0ms preprocess, 200.0ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0173.jpg: 352x640 3 persons, 203.9ms\n",
            "Speed: 4.0ms preprocess, 203.9ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0174.jpg: 352x640 3 persons, 194.4ms\n",
            "Speed: 4.1ms preprocess, 194.4ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0175.jpg: 352x640 3 persons, 201.0ms\n",
            "Speed: 4.0ms preprocess, 201.0ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0176.jpg: 352x640 3 persons, 209.7ms\n",
            "Speed: 4.1ms preprocess, 209.7ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0177.jpg: 352x640 3 persons, 210.0ms\n",
            "Speed: 4.4ms preprocess, 210.0ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0178.jpg: 352x640 3 persons, 206.6ms\n",
            "Speed: 4.0ms preprocess, 206.6ms inference, 2.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0179.jpg: 352x640 3 persons, 125.7ms\n",
            "Speed: 2.8ms preprocess, 125.7ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0180.jpg: 352x640 3 persons, 136.7ms\n",
            "Speed: 3.0ms preprocess, 136.7ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0181.jpg: 352x640 3 persons, 130.5ms\n",
            "Speed: 2.8ms preprocess, 130.5ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0182.jpg: 352x640 4 persons, 128.5ms\n",
            "Speed: 2.8ms preprocess, 128.5ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0183.jpg: 352x640 4 persons, 127.4ms\n",
            "Speed: 3.0ms preprocess, 127.4ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0184.jpg: 352x640 3 persons, 143.5ms\n",
            "Speed: 3.4ms preprocess, 143.5ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0185.jpg: 352x640 4 persons, 138.3ms\n",
            "Speed: 3.1ms preprocess, 138.3ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0186.jpg: 352x640 4 persons, 129.0ms\n",
            "Speed: 2.8ms preprocess, 129.0ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0187.jpg: 352x640 4 persons, 129.4ms\n",
            "Speed: 2.9ms preprocess, 129.4ms inference, 3.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0188.jpg: 352x640 4 persons, 125.7ms\n",
            "Speed: 2.8ms preprocess, 125.7ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0189.jpg: 352x640 4 persons, 134.9ms\n",
            "Speed: 2.8ms preprocess, 134.9ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0190.jpg: 352x640 4 persons, 128.1ms\n",
            "Speed: 3.0ms preprocess, 128.1ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0191.jpg: 352x640 4 persons, 139.0ms\n",
            "Speed: 2.8ms preprocess, 139.0ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0192.jpg: 352x640 4 persons, 132.3ms\n",
            "Speed: 2.8ms preprocess, 132.3ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0193.jpg: 352x640 4 persons, 125.1ms\n",
            "Speed: 3.0ms preprocess, 125.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0194.jpg: 352x640 3 persons, 138.5ms\n",
            "Speed: 2.7ms preprocess, 138.5ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0195.jpg: 352x640 2 persons, 125.8ms\n",
            "Speed: 2.8ms preprocess, 125.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0196.jpg: 352x640 2 persons, 137.5ms\n",
            "Speed: 3.0ms preprocess, 137.5ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0197.jpg: 352x640 2 persons, 131.8ms\n",
            "Speed: 2.8ms preprocess, 131.8ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0198.jpg: 352x640 2 persons, 127.2ms\n",
            "Speed: 2.8ms preprocess, 127.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0199.jpg: 352x640 2 persons, 127.2ms\n",
            "Speed: 3.0ms preprocess, 127.2ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0200.jpg: 352x640 2 persons, 127.0ms\n",
            "Speed: 3.2ms preprocess, 127.0ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0201.jpg: 352x640 2 persons, 128.0ms\n",
            "Speed: 2.8ms preprocess, 128.0ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0202.jpg: 352x640 2 persons, 132.4ms\n",
            "Speed: 4.3ms preprocess, 132.4ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0203.jpg: 352x640 2 persons, 129.1ms\n",
            "Speed: 3.5ms preprocess, 129.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0204.jpg: 352x640 3 persons, 127.0ms\n",
            "Speed: 2.9ms preprocess, 127.0ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0205.jpg: 352x640 3 persons, 136.2ms\n",
            "Speed: 2.8ms preprocess, 136.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0206.jpg: 352x640 3 persons, 128.5ms\n",
            "Speed: 3.1ms preprocess, 128.5ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0207.jpg: 352x640 3 persons, 139.0ms\n",
            "Speed: 2.8ms preprocess, 139.0ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0208.jpg: 352x640 3 persons, 128.8ms\n",
            "Speed: 3.1ms preprocess, 128.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0209.jpg: 352x640 3 persons, 126.2ms\n",
            "Speed: 2.8ms preprocess, 126.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0210.jpg: 352x640 3 persons, 136.0ms\n",
            "Speed: 2.8ms preprocess, 136.0ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0211.jpg: 352x640 4 persons, 127.3ms\n",
            "Speed: 3.1ms preprocess, 127.3ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0212.jpg: 352x640 4 persons, 127.5ms\n",
            "Speed: 2.8ms preprocess, 127.5ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0213.jpg: 352x640 4 persons, 130.1ms\n",
            "Speed: 2.9ms preprocess, 130.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0214.jpg: 352x640 4 persons, 126.2ms\n",
            "Speed: 2.9ms preprocess, 126.2ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0215.jpg: 352x640 4 persons, 130.8ms\n",
            "Speed: 2.7ms preprocess, 130.8ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0216.jpg: 352x640 4 persons, 125.7ms\n",
            "Speed: 2.7ms preprocess, 125.7ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0217.jpg: 352x640 4 persons, 124.3ms\n",
            "Speed: 2.9ms preprocess, 124.3ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0218.jpg: 352x640 4 persons, 138.9ms\n",
            "Speed: 2.9ms preprocess, 138.9ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0219.jpg: 352x640 4 persons, 127.2ms\n",
            "Speed: 3.9ms preprocess, 127.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0220.jpg: 352x640 3 persons, 128.0ms\n",
            "Speed: 3.1ms preprocess, 128.0ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0221.jpg: 352x640 3 persons, 130.6ms\n",
            "Speed: 3.2ms preprocess, 130.6ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0222.jpg: 352x640 3 persons, 124.7ms\n",
            "Speed: 2.9ms preprocess, 124.7ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0223.jpg: 352x640 3 persons, 127.2ms\n",
            "Speed: 2.8ms preprocess, 127.2ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0224.jpg: 352x640 3 persons, 129.5ms\n",
            "Speed: 3.0ms preprocess, 129.5ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0225.jpg: 352x640 3 persons, 125.9ms\n",
            "Speed: 2.8ms preprocess, 125.9ms inference, 1.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0226.jpg: 352x640 5 persons, 136.9ms\n",
            "Speed: 2.9ms preprocess, 136.9ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0227.jpg: 352x640 3 persons, 125.9ms\n",
            "Speed: 2.9ms preprocess, 125.9ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0228.jpg: 352x640 3 persons, 124.0ms\n",
            "Speed: 2.8ms preprocess, 124.0ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0229.jpg: 352x640 3 persons, 138.9ms\n",
            "Speed: 2.8ms preprocess, 138.9ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0230.jpg: 352x640 2 persons, 126.7ms\n",
            "Speed: 3.0ms preprocess, 126.7ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0231.jpg: 352x640 2 persons, 132.0ms\n",
            "Speed: 2.9ms preprocess, 132.0ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0232.jpg: 352x640 3 persons, 200.0ms\n",
            "Speed: 4.1ms preprocess, 200.0ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0233.jpg: 352x640 3 persons, 197.1ms\n",
            "Speed: 4.1ms preprocess, 197.1ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0234.jpg: 352x640 3 persons, 207.5ms\n",
            "Speed: 3.9ms preprocess, 207.5ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0235.jpg: 352x640 3 persons, 200.8ms\n",
            "Speed: 4.1ms preprocess, 200.8ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0236.jpg: 352x640 3 persons, 191.3ms\n",
            "Speed: 4.2ms preprocess, 191.3ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0237.jpg: 352x640 4 persons, 200.7ms\n",
            "Speed: 4.1ms preprocess, 200.7ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0238.jpg: 352x640 4 persons, 200.9ms\n",
            "Speed: 4.1ms preprocess, 200.9ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0239.jpg: 352x640 3 persons, 195.6ms\n",
            "Speed: 4.1ms preprocess, 195.6ms inference, 1.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0240.jpg: 352x640 2 persons, 199.5ms\n",
            "Speed: 4.0ms preprocess, 199.5ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0241.jpg: 352x640 4 persons, 203.3ms\n",
            "Speed: 3.9ms preprocess, 203.3ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0242.jpg: 352x640 2 persons, 132.2ms\n",
            "Speed: 2.9ms preprocess, 132.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0243.jpg: 352x640 2 persons, 125.8ms\n",
            "Speed: 2.8ms preprocess, 125.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0244.jpg: 352x640 3 persons, 126.1ms\n",
            "Speed: 2.8ms preprocess, 126.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0245.jpg: 352x640 3 persons, 129.5ms\n",
            "Speed: 3.0ms preprocess, 129.5ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0246.jpg: 352x640 2 persons, 133.2ms\n",
            "Speed: 2.8ms preprocess, 133.2ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0247.jpg: 352x640 3 persons, 127.9ms\n",
            "Speed: 2.8ms preprocess, 127.9ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0248.jpg: 352x640 3 persons, 141.2ms\n",
            "Speed: 3.6ms preprocess, 141.2ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0249.jpg: 352x640 4 persons, 126.4ms\n",
            "Speed: 2.8ms preprocess, 126.4ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0250.jpg: 352x640 4 persons, 129.8ms\n",
            "Speed: 3.0ms preprocess, 129.8ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0251.jpg: 352x640 3 persons, 131.1ms\n",
            "Speed: 2.8ms preprocess, 131.1ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0252.jpg: 352x640 2 persons, 138.7ms\n",
            "Speed: 2.9ms preprocess, 138.7ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0253.jpg: 352x640 3 persons, 133.2ms\n",
            "Speed: 2.9ms preprocess, 133.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0254.jpg: 352x640 3 persons, 125.2ms\n",
            "Speed: 2.8ms preprocess, 125.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0255.jpg: 352x640 4 persons, 125.1ms\n",
            "Speed: 2.9ms preprocess, 125.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0256.jpg: 352x640 4 persons, 125.5ms\n",
            "Speed: 2.9ms preprocess, 125.5ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0257.jpg: 352x640 3 persons, 133.8ms\n",
            "Speed: 3.7ms preprocess, 133.8ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0258.jpg: 352x640 3 persons, 139.0ms\n",
            "Speed: 3.2ms preprocess, 139.0ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0259.jpg: 352x640 3 persons, 128.4ms\n",
            "Speed: 3.0ms preprocess, 128.4ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0260.jpg: 352x640 3 persons, 124.8ms\n",
            "Speed: 2.8ms preprocess, 124.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0261.jpg: 352x640 2 persons, 130.8ms\n",
            "Speed: 2.8ms preprocess, 130.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0262.jpg: 352x640 3 persons, 129.3ms\n",
            "Speed: 2.9ms preprocess, 129.3ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0263.jpg: 352x640 2 persons, 140.1ms\n",
            "Speed: 2.8ms preprocess, 140.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0264.jpg: 352x640 3 persons, 124.7ms\n",
            "Speed: 3.1ms preprocess, 124.7ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0265.jpg: 352x640 3 persons, 123.2ms\n",
            "Speed: 2.8ms preprocess, 123.2ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0266.jpg: 352x640 3 persons, 127.3ms\n",
            "Speed: 2.9ms preprocess, 127.3ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0267.jpg: 352x640 2 persons, 124.9ms\n",
            "Speed: 2.8ms preprocess, 124.9ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0268.jpg: 352x640 2 persons, 125.9ms\n",
            "Speed: 2.8ms preprocess, 125.9ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0269.jpg: 352x640 2 persons, 133.3ms\n",
            "Speed: 3.1ms preprocess, 133.3ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0270.jpg: 352x640 3 persons, 126.7ms\n",
            "Speed: 2.8ms preprocess, 126.7ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0271.jpg: 352x640 3 persons, 127.2ms\n",
            "Speed: 2.9ms preprocess, 127.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0272.jpg: 352x640 4 persons, 136.1ms\n",
            "Speed: 3.0ms preprocess, 136.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0273.jpg: 352x640 4 persons, 128.9ms\n",
            "Speed: 2.8ms preprocess, 128.9ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0274.jpg: 352x640 5 persons, 148.2ms\n",
            "Speed: 2.8ms preprocess, 148.2ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0275.jpg: 352x640 4 persons, 127.5ms\n",
            "Speed: 3.0ms preprocess, 127.5ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0276.jpg: 352x640 3 persons, 133.4ms\n",
            "Speed: 2.9ms preprocess, 133.4ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0277.jpg: 352x640 4 persons, 132.2ms\n",
            "Speed: 2.9ms preprocess, 132.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0278.jpg: 352x640 4 persons, 130.6ms\n",
            "Speed: 2.9ms preprocess, 130.6ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0279.jpg: 352x640 4 persons, 162.6ms\n",
            "Speed: 2.7ms preprocess, 162.6ms inference, 1.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0280.jpg: 352x640 4 persons, 131.2ms\n",
            "Speed: 2.8ms preprocess, 131.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0281.jpg: 352x640 4 persons, 126.4ms\n",
            "Speed: 3.0ms preprocess, 126.4ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0282.jpg: 352x640 4 persons, 126.9ms\n",
            "Speed: 2.8ms preprocess, 126.9ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0283.jpg: 352x640 3 persons, 131.2ms\n",
            "Speed: 2.9ms preprocess, 131.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0284.jpg: 352x640 3 persons, 124.7ms\n",
            "Speed: 2.9ms preprocess, 124.7ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0285.jpg: 352x640 3 persons, 142.3ms\n",
            "Speed: 3.4ms preprocess, 142.3ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0286.jpg: 352x640 3 persons, 125.3ms\n",
            "Speed: 2.9ms preprocess, 125.3ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0287.jpg: 352x640 5 persons, 128.8ms\n",
            "Speed: 2.9ms preprocess, 128.8ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0288.jpg: 352x640 5 persons, 127.2ms\n",
            "Speed: 2.7ms preprocess, 127.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0289.jpg: 352x640 5 persons, 124.4ms\n",
            "Speed: 4.0ms preprocess, 124.4ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0290.jpg: 352x640 4 persons, 146.8ms\n",
            "Speed: 2.9ms preprocess, 146.8ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0291.jpg: 352x640 4 persons, 126.8ms\n",
            "Speed: 2.8ms preprocess, 126.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0292.jpg: 352x640 4 persons, 125.2ms\n",
            "Speed: 2.9ms preprocess, 125.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0293.jpg: 352x640 3 persons, 127.7ms\n",
            "Speed: 3.0ms preprocess, 127.7ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0294.jpg: 352x640 4 persons, 126.8ms\n",
            "Speed: 2.7ms preprocess, 126.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0295.jpg: 352x640 4 persons, 218.6ms\n",
            "Speed: 4.4ms preprocess, 218.6ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0296.jpg: 352x640 3 persons, 194.7ms\n",
            "Speed: 4.1ms preprocess, 194.7ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0297.jpg: 352x640 3 persons, 192.8ms\n",
            "Speed: 4.0ms preprocess, 192.8ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0298.jpg: 352x640 3 persons, 192.6ms\n",
            "Speed: 5.7ms preprocess, 192.6ms inference, 3.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0299.jpg: 352x640 3 persons, 199.7ms\n",
            "Speed: 4.2ms preprocess, 199.7ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0300.jpg: 352x640 4 persons, 191.1ms\n",
            "Speed: 4.0ms preprocess, 191.1ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0301.jpg: 352x640 3 persons, 205.4ms\n",
            "Speed: 4.2ms preprocess, 205.4ms inference, 4.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0302.jpg: 352x640 3 persons, 207.9ms\n",
            "Speed: 4.0ms preprocess, 207.9ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0303.jpg: 352x640 3 persons, 208.7ms\n",
            "Speed: 4.0ms preprocess, 208.7ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0304.jpg: 352x640 3 persons, 190.0ms\n",
            "Speed: 4.6ms preprocess, 190.0ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0305.jpg: 352x640 4 persons, 128.5ms\n",
            "Speed: 3.0ms preprocess, 128.5ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0306.jpg: 352x640 4 persons, 141.3ms\n",
            "Speed: 2.8ms preprocess, 141.3ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0307.jpg: 352x640 4 persons, 126.6ms\n",
            "Speed: 2.8ms preprocess, 126.6ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0308.jpg: 352x640 4 persons, 137.6ms\n",
            "Speed: 3.0ms preprocess, 137.6ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0309.jpg: 352x640 4 persons, 126.2ms\n",
            "Speed: 2.8ms preprocess, 126.2ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0310.jpg: 352x640 4 persons, 131.7ms\n",
            "Speed: 2.8ms preprocess, 131.7ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0311.jpg: 352x640 4 persons, 127.7ms\n",
            "Speed: 3.0ms preprocess, 127.7ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0312.jpg: 352x640 3 persons, 129.5ms\n",
            "Speed: 3.4ms preprocess, 129.5ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0313.jpg: 352x640 3 persons, 134.7ms\n",
            "Speed: 3.0ms preprocess, 134.7ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0314.jpg: 352x640 3 persons, 123.7ms\n",
            "Speed: 2.9ms preprocess, 123.7ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0315.jpg: 352x640 3 persons, 124.8ms\n",
            "Speed: 2.8ms preprocess, 124.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0316.jpg: 352x640 3 persons, 126.6ms\n",
            "Speed: 3.1ms preprocess, 126.6ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0317.jpg: 352x640 3 persons, 142.4ms\n",
            "Speed: 2.8ms preprocess, 142.4ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0318.jpg: 352x640 3 persons, 124.5ms\n",
            "Speed: 2.8ms preprocess, 124.5ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0319.jpg: 352x640 3 persons, 135.8ms\n",
            "Speed: 2.9ms preprocess, 135.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0320.jpg: 352x640 3 persons, 128.7ms\n",
            "Speed: 2.8ms preprocess, 128.7ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0321.jpg: 352x640 3 persons, 127.3ms\n",
            "Speed: 2.8ms preprocess, 127.3ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0322.jpg: 352x640 3 persons, 127.6ms\n",
            "Speed: 2.9ms preprocess, 127.6ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0323.jpg: 352x640 3 persons, 124.9ms\n",
            "Speed: 2.7ms preprocess, 124.9ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0324.jpg: 352x640 3 persons, 123.9ms\n",
            "Speed: 2.8ms preprocess, 123.9ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0325.jpg: 352x640 3 persons, 125.7ms\n",
            "Speed: 2.8ms preprocess, 125.7ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0326.jpg: 352x640 3 persons, 133.9ms\n",
            "Speed: 2.8ms preprocess, 133.9ms inference, 1.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0327.jpg: 352x640 3 persons, 127.0ms\n",
            "Speed: 3.3ms preprocess, 127.0ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0328.jpg: 352x640 3 persons, 136.1ms\n",
            "Speed: 3.0ms preprocess, 136.1ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0329.jpg: 352x640 3 persons, 126.1ms\n",
            "Speed: 2.7ms preprocess, 126.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0330.jpg: 352x640 3 persons, 135.9ms\n",
            "Speed: 2.9ms preprocess, 135.9ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0331.jpg: 352x640 3 persons, 128.6ms\n",
            "Speed: 2.8ms preprocess, 128.6ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0332.jpg: 352x640 3 persons, 129.1ms\n",
            "Speed: 2.8ms preprocess, 129.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0333.jpg: 352x640 3 persons, 138.1ms\n",
            "Speed: 3.0ms preprocess, 138.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0334.jpg: 352x640 3 persons, 127.7ms\n",
            "Speed: 2.8ms preprocess, 127.7ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0335.jpg: 352x640 3 persons, 125.1ms\n",
            "Speed: 2.8ms preprocess, 125.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0336.jpg: 352x640 3 persons, 131.3ms\n",
            "Speed: 3.0ms preprocess, 131.3ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0337.jpg: 352x640 3 persons, 129.1ms\n",
            "Speed: 2.9ms preprocess, 129.1ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0338.jpg: 352x640 3 persons, 126.0ms\n",
            "Speed: 2.8ms preprocess, 126.0ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0339.jpg: 352x640 3 persons, 126.6ms\n",
            "Speed: 3.1ms preprocess, 126.6ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0340.jpg: 352x640 3 persons, 123.9ms\n",
            "Speed: 2.8ms preprocess, 123.9ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0341.jpg: 352x640 3 persons, 136.9ms\n",
            "Speed: 2.9ms preprocess, 136.9ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0342.jpg: 352x640 3 persons, 125.8ms\n",
            "Speed: 2.8ms preprocess, 125.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0343.jpg: 352x640 3 persons, 127.5ms\n",
            "Speed: 2.9ms preprocess, 127.5ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0344.jpg: 352x640 3 persons, 132.6ms\n",
            "Speed: 2.9ms preprocess, 132.6ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0345.jpg: 352x640 3 persons, 124.5ms\n",
            "Speed: 2.8ms preprocess, 124.5ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0346.jpg: 352x640 3 persons, 124.0ms\n",
            "Speed: 2.8ms preprocess, 124.0ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0347.jpg: 352x640 3 persons, 126.2ms\n",
            "Speed: 3.0ms preprocess, 126.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0348.jpg: 352x640 3 persons, 129.0ms\n",
            "Speed: 2.9ms preprocess, 129.0ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0349.jpg: 352x640 3 persons, 134.8ms\n",
            "Speed: 2.9ms preprocess, 134.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0350.jpg: 352x640 3 persons, 125.2ms\n",
            "Speed: 3.0ms preprocess, 125.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0351.jpg: 352x640 3 persons, 124.4ms\n",
            "Speed: 2.8ms preprocess, 124.4ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0352.jpg: 352x640 3 persons, 141.6ms\n",
            "Speed: 2.9ms preprocess, 141.6ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0353.jpg: 352x640 3 persons, 125.2ms\n",
            "Speed: 3.0ms preprocess, 125.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0354.jpg: 352x640 3 persons, 130.4ms\n",
            "Speed: 3.0ms preprocess, 130.4ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0355.jpg: 352x640 3 persons, 129.1ms\n",
            "Speed: 3.4ms preprocess, 129.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0356.jpg: 352x640 3 persons, 129.0ms\n",
            "Speed: 2.8ms preprocess, 129.0ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0357.jpg: 352x640 3 persons, 126.2ms\n",
            "Speed: 2.8ms preprocess, 126.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0358.jpg: 352x640 3 persons, 187.6ms\n",
            "Speed: 4.2ms preprocess, 187.6ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0359.jpg: 352x640 3 persons, 203.7ms\n",
            "Speed: 4.0ms preprocess, 203.7ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0360.jpg: 352x640 3 persons, 192.3ms\n",
            "Speed: 4.1ms preprocess, 192.3ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0361.jpg: 352x640 3 persons, 196.9ms\n",
            "Speed: 4.1ms preprocess, 196.9ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0362.jpg: 352x640 3 persons, 203.2ms\n",
            "Speed: 4.0ms preprocess, 203.2ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0363.jpg: 352x640 4 persons, 200.5ms\n",
            "Speed: 4.0ms preprocess, 200.5ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0364.jpg: 352x640 3 persons, 193.2ms\n",
            "Speed: 3.9ms preprocess, 193.2ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0365.jpg: 352x640 3 persons, 209.5ms\n",
            "Speed: 4.2ms preprocess, 209.5ms inference, 2.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0366.jpg: 352x640 4 persons, 212.7ms\n",
            "Speed: 4.1ms preprocess, 212.7ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0367.jpg: 352x640 4 persons, 198.1ms\n",
            "Speed: 4.0ms preprocess, 198.1ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0368.jpg: 352x640 3 persons, 134.2ms\n",
            "Speed: 4.0ms preprocess, 134.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0369.jpg: 352x640 3 persons, 124.7ms\n",
            "Speed: 2.8ms preprocess, 124.7ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0370.jpg: 352x640 3 persons, 139.2ms\n",
            "Speed: 2.8ms preprocess, 139.2ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0371.jpg: 352x640 3 persons, 132.7ms\n",
            "Speed: 2.9ms preprocess, 132.7ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0372.jpg: 352x640 2 persons, 124.5ms\n",
            "Speed: 2.8ms preprocess, 124.5ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0373.jpg: 352x640 3 persons, 125.1ms\n",
            "Speed: 2.8ms preprocess, 125.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0374.jpg: 352x640 3 persons, 126.6ms\n",
            "Speed: 3.0ms preprocess, 126.6ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0375.jpg: 352x640 3 persons, 127.1ms\n",
            "Speed: 2.8ms preprocess, 127.1ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0376.jpg: 352x640 3 persons, 129.7ms\n",
            "Speed: 2.8ms preprocess, 129.7ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0377.jpg: 352x640 3 persons, 132.7ms\n",
            "Speed: 3.0ms preprocess, 132.7ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0378.jpg: 352x640 3 persons, 124.1ms\n",
            "Speed: 2.8ms preprocess, 124.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0379.jpg: 352x640 3 persons, 125.3ms\n",
            "Speed: 2.8ms preprocess, 125.3ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0380.jpg: 352x640 3 persons, 128.2ms\n",
            "Speed: 2.7ms preprocess, 128.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0381.jpg: 352x640 3 persons, 138.2ms\n",
            "Speed: 2.8ms preprocess, 138.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0382.jpg: 352x640 3 persons, 145.8ms\n",
            "Speed: 2.9ms preprocess, 145.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0383.jpg: 352x640 3 persons, 126.6ms\n",
            "Speed: 2.8ms preprocess, 126.6ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0384.jpg: 352x640 3 persons, 125.5ms\n",
            "Speed: 2.7ms preprocess, 125.5ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0385.jpg: 352x640 3 persons, 124.8ms\n",
            "Speed: 2.9ms preprocess, 124.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0386.jpg: 352x640 3 persons, 128.6ms\n",
            "Speed: 2.8ms preprocess, 128.6ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0387.jpg: 352x640 3 persons, 133.4ms\n",
            "Speed: 2.7ms preprocess, 133.4ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0388.jpg: 352x640 3 persons, 124.8ms\n",
            "Speed: 2.9ms preprocess, 124.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0389.jpg: 352x640 3 persons, 124.5ms\n",
            "Speed: 2.8ms preprocess, 124.5ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0390.jpg: 352x640 3 persons, 125.6ms\n",
            "Speed: 2.9ms preprocess, 125.6ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0391.jpg: 352x640 3 persons, 127.3ms\n",
            "Speed: 2.9ms preprocess, 127.3ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0392.jpg: 352x640 3 persons, 142.4ms\n",
            "Speed: 2.8ms preprocess, 142.4ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0393.jpg: 352x640 3 persons, 123.8ms\n",
            "Speed: 2.7ms preprocess, 123.8ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0394.jpg: 352x640 3 persons, 127.3ms\n",
            "Speed: 2.7ms preprocess, 127.3ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0395.jpg: 352x640 3 persons, 124.2ms\n",
            "Speed: 2.9ms preprocess, 124.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0396.jpg: 352x640 3 persons, 124.0ms\n",
            "Speed: 2.8ms preprocess, 124.0ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0397.jpg: 352x640 3 persons, 124.1ms\n",
            "Speed: 2.8ms preprocess, 124.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0398.jpg: 352x640 3 persons, 138.8ms\n",
            "Speed: 4.0ms preprocess, 138.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0399.jpg: 352x640 3 persons, 124.3ms\n",
            "Speed: 2.8ms preprocess, 124.3ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0400.jpg: 352x640 4 persons, 126.1ms\n",
            "Speed: 2.8ms preprocess, 126.1ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0401.jpg: 352x640 4 persons, 123.6ms\n",
            "Speed: 2.8ms preprocess, 123.6ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0402.jpg: 352x640 4 persons, 128.9ms\n",
            "Speed: 2.8ms preprocess, 128.9ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0403.jpg: 352x640 4 persons, 143.2ms\n",
            "Speed: 2.8ms preprocess, 143.2ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0404.jpg: 352x640 4 persons, 125.6ms\n",
            "Speed: 2.8ms preprocess, 125.6ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0405.jpg: 352x640 4 persons, 124.5ms\n",
            "Speed: 2.7ms preprocess, 124.5ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0406.jpg: 352x640 4 persons, 125.6ms\n",
            "Speed: 2.8ms preprocess, 125.6ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0407.jpg: 352x640 4 persons, 129.8ms\n",
            "Speed: 2.9ms preprocess, 129.8ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0408.jpg: 352x640 4 persons, 138.7ms\n",
            "Speed: 2.9ms preprocess, 138.7ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0409.jpg: 352x640 4 persons, 144.0ms\n",
            "Speed: 4.0ms preprocess, 144.0ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0410.jpg: 352x640 4 persons, 124.6ms\n",
            "Speed: 3.0ms preprocess, 124.6ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0411.jpg: 352x640 3 persons, 125.4ms\n",
            "Speed: 2.8ms preprocess, 125.4ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0412.jpg: 352x640 3 persons, 126.9ms\n",
            "Speed: 2.8ms preprocess, 126.9ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0413.jpg: 352x640 3 persons, 124.3ms\n",
            "Speed: 2.8ms preprocess, 124.3ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0414.jpg: 352x640 3 persons, 145.4ms\n",
            "Speed: 3.7ms preprocess, 145.4ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0415.jpg: 352x640 4 persons, 124.2ms\n",
            "Speed: 2.8ms preprocess, 124.2ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0416.jpg: 352x640 3 persons, 125.1ms\n",
            "Speed: 2.8ms preprocess, 125.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0417.jpg: 352x640 3 persons, 125.1ms\n",
            "Speed: 2.8ms preprocess, 125.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0418.jpg: 352x640 3 persons, 126.6ms\n",
            "Speed: 2.8ms preprocess, 126.6ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0419.jpg: 352x640 3 persons, 130.9ms\n",
            "Speed: 2.9ms preprocess, 130.9ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0420.jpg: 352x640 3 persons, 137.1ms\n",
            "Speed: 2.9ms preprocess, 137.1ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0421.jpg: 352x640 3 persons, 124.1ms\n",
            "Speed: 2.9ms preprocess, 124.1ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0422.jpg: 352x640 3 persons, 201.4ms\n",
            "Speed: 3.9ms preprocess, 201.4ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0423.jpg: 352x640 3 persons, 201.8ms\n",
            "Speed: 4.0ms preprocess, 201.8ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0424.jpg: 352x640 3 persons, 214.4ms\n",
            "Speed: 4.0ms preprocess, 214.4ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0425.jpg: 352x640 3 persons, 196.0ms\n",
            "Speed: 4.1ms preprocess, 196.0ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0426.jpg: 352x640 3 persons, 200.5ms\n",
            "Speed: 4.1ms preprocess, 200.5ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0427.jpg: 352x640 3 persons, 205.9ms\n",
            "Speed: 4.2ms preprocess, 205.9ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0428.jpg: 352x640 3 persons, 209.1ms\n",
            "Speed: 4.1ms preprocess, 209.1ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0429.jpg: 352x640 3 persons, 212.6ms\n",
            "Speed: 4.4ms preprocess, 212.6ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0430.jpg: 352x640 3 persons, 209.8ms\n",
            "Speed: 4.0ms preprocess, 209.8ms inference, 1.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0431.jpg: 352x640 3 persons, 205.4ms\n",
            "Speed: 5.4ms preprocess, 205.4ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0432.jpg: 352x640 3 persons, 148.3ms\n",
            "Speed: 4.7ms preprocess, 148.3ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0433.jpg: 352x640 4 persons, 124.7ms\n",
            "Speed: 2.8ms preprocess, 124.7ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0434.jpg: 352x640 4 persons, 126.5ms\n",
            "Speed: 2.8ms preprocess, 126.5ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0435.jpg: 352x640 3 persons, 133.7ms\n",
            "Speed: 3.0ms preprocess, 133.7ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0436.jpg: 352x640 4 persons, 127.1ms\n",
            "Speed: 2.8ms preprocess, 127.1ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0437.jpg: 352x640 4 persons, 137.7ms\n",
            "Speed: 2.8ms preprocess, 137.7ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0438.jpg: 352x640 2 persons, 128.3ms\n",
            "Speed: 3.0ms preprocess, 128.3ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0439.jpg: 352x640 2 persons, 127.7ms\n",
            "Speed: 2.8ms preprocess, 127.7ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0440.jpg: 352x640 3 persons, 129.6ms\n",
            "Speed: 2.8ms preprocess, 129.6ms inference, 2.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0441.jpg: 352x640 3 persons, 138.6ms\n",
            "Speed: 3.5ms preprocess, 138.6ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0442.jpg: 352x640 2 persons, 138.2ms\n",
            "Speed: 2.8ms preprocess, 138.2ms inference, 1.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0443.jpg: 352x640 2 persons, 129.5ms\n",
            "Speed: 2.9ms preprocess, 129.5ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0444.jpg: 352x640 3 persons, 126.0ms\n",
            "Speed: 2.9ms preprocess, 126.0ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0445.jpg: 352x640 3 persons, 125.7ms\n",
            "Speed: 2.8ms preprocess, 125.7ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0446.jpg: 352x640 4 persons, 135.6ms\n",
            "Speed: 3.3ms preprocess, 135.6ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0447.jpg: 352x640 3 persons, 126.2ms\n",
            "Speed: 2.9ms preprocess, 126.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0448.jpg: 352x640 3 persons, 136.6ms\n",
            "Speed: 2.8ms preprocess, 136.6ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0449.jpg: 352x640 3 persons, 126.5ms\n",
            "Speed: 2.8ms preprocess, 126.5ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0450.jpg: 352x640 3 persons, 129.6ms\n",
            "Speed: 2.8ms preprocess, 129.6ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0451.jpg: 352x640 4 persons, 133.6ms\n",
            "Speed: 2.9ms preprocess, 133.6ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0452.jpg: 352x640 4 persons, 129.8ms\n",
            "Speed: 3.0ms preprocess, 129.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0453.jpg: 352x640 4 persons, 126.8ms\n",
            "Speed: 2.8ms preprocess, 126.8ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0454.jpg: 352x640 4 persons, 125.4ms\n",
            "Speed: 3.0ms preprocess, 125.4ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0455.jpg: 352x640 4 persons, 126.2ms\n",
            "Speed: 2.8ms preprocess, 126.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0456.jpg: 352x640 4 persons, 125.3ms\n",
            "Speed: 2.8ms preprocess, 125.3ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0457.jpg: 352x640 4 persons, 135.5ms\n",
            "Speed: 3.4ms preprocess, 135.5ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0458.jpg: 352x640 4 persons, 125.8ms\n",
            "Speed: 2.8ms preprocess, 125.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0459.jpg: 352x640 4 persons, 138.8ms\n",
            "Speed: 2.8ms preprocess, 138.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0460.jpg: 352x640 4 persons, 125.2ms\n",
            "Speed: 2.8ms preprocess, 125.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0461.jpg: 352x640 4 persons, 124.5ms\n",
            "Speed: 2.9ms preprocess, 124.5ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0462.jpg: 352x640 4 persons, 137.3ms\n",
            "Speed: 2.8ms preprocess, 137.3ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0463.jpg: 352x640 4 persons, 124.7ms\n",
            "Speed: 2.8ms preprocess, 124.7ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0464.jpg: 352x640 4 persons, 125.0ms\n",
            "Speed: 2.9ms preprocess, 125.0ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0465.jpg: 352x640 4 persons, 125.4ms\n",
            "Speed: 2.8ms preprocess, 125.4ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0466.jpg: 352x640 4 persons, 127.8ms\n",
            "Speed: 2.9ms preprocess, 127.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0467.jpg: 352x640 4 persons, 125.2ms\n",
            "Speed: 2.9ms preprocess, 125.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0468.jpg: 352x640 4 persons, 124.7ms\n",
            "Speed: 3.4ms preprocess, 124.7ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0469.jpg: 352x640 4 persons, 124.9ms\n",
            "Speed: 2.9ms preprocess, 124.9ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0470.jpg: 352x640 4 persons, 137.2ms\n",
            "Speed: 2.8ms preprocess, 137.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0471.jpg: 352x640 4 persons, 128.1ms\n",
            "Speed: 2.8ms preprocess, 128.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0472.jpg: 352x640 4 persons, 123.9ms\n",
            "Speed: 2.8ms preprocess, 123.9ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0473.jpg: 352x640 4 persons, 134.1ms\n",
            "Speed: 2.8ms preprocess, 134.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0474.jpg: 352x640 4 persons, 124.4ms\n",
            "Speed: 2.8ms preprocess, 124.4ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0475.jpg: 352x640 4 persons, 125.3ms\n",
            "Speed: 2.8ms preprocess, 125.3ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0476.jpg: 352x640 4 persons, 141.0ms\n",
            "Speed: 2.9ms preprocess, 141.0ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0477.jpg: 352x640 4 persons, 126.5ms\n",
            "Speed: 2.8ms preprocess, 126.5ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0478.jpg: 352x640 4 persons, 129.2ms\n",
            "Speed: 2.9ms preprocess, 129.2ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0479.jpg: 352x640 4 persons, 124.7ms\n",
            "Speed: 2.8ms preprocess, 124.7ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0480.jpg: 352x640 5 persons, 123.9ms\n",
            "Speed: 2.8ms preprocess, 123.9ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0481.jpg: 352x640 4 persons, 129.4ms\n",
            "Speed: 2.7ms preprocess, 129.4ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0482.jpg: 352x640 5 persons, 131.1ms\n",
            "Speed: 2.8ms preprocess, 131.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0483.jpg: 352x640 3 persons, 133.2ms\n",
            "Speed: 2.9ms preprocess, 133.2ms inference, 2.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0484.jpg: 352x640 3 persons, 140.3ms\n",
            "Speed: 3.3ms preprocess, 140.3ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0485.jpg: 352x640 4 persons, 124.7ms\n",
            "Speed: 2.8ms preprocess, 124.7ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0486.jpg: 352x640 5 persons, 205.0ms\n",
            "Speed: 4.1ms preprocess, 205.0ms inference, 5.3ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0487.jpg: 352x640 4 persons, 197.1ms\n",
            "Speed: 4.1ms preprocess, 197.1ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0488.jpg: 352x640 4 persons, 207.1ms\n",
            "Speed: 4.0ms preprocess, 207.1ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0489.jpg: 352x640 4 persons, 195.2ms\n",
            "Speed: 4.1ms preprocess, 195.2ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0490.jpg: 352x640 4 persons, 205.6ms\n",
            "Speed: 4.1ms preprocess, 205.6ms inference, 2.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0491.jpg: 352x640 4 persons, 193.8ms\n",
            "Speed: 4.0ms preprocess, 193.8ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0492.jpg: 352x640 4 persons, 200.4ms\n",
            "Speed: 4.2ms preprocess, 200.4ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0493.jpg: 352x640 4 persons, 200.2ms\n",
            "Speed: 3.9ms preprocess, 200.2ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0494.jpg: 352x640 4 persons, 217.8ms\n",
            "Speed: 3.9ms preprocess, 217.8ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0495.jpg: 352x640 4 persons, 205.6ms\n",
            "Speed: 3.8ms preprocess, 205.6ms inference, 1.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0496.jpg: 352x640 4 persons, 160.1ms\n",
            "Speed: 3.9ms preprocess, 160.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0497.jpg: 352x640 4 persons, 124.4ms\n",
            "Speed: 2.7ms preprocess, 124.4ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0498.jpg: 352x640 4 persons, 128.5ms\n",
            "Speed: 2.8ms preprocess, 128.5ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0499.jpg: 352x640 4 persons, 136.2ms\n",
            "Speed: 3.1ms preprocess, 136.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0500.jpg: 352x640 5 persons, 135.3ms\n",
            "Speed: 2.7ms preprocess, 135.3ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0501.jpg: 352x640 4 persons, 127.6ms\n",
            "Speed: 3.2ms preprocess, 127.6ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0502.jpg: 352x640 4 persons, 124.6ms\n",
            "Speed: 2.9ms preprocess, 124.6ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0503.jpg: 352x640 4 persons, 127.6ms\n",
            "Speed: 3.0ms preprocess, 127.6ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0504.jpg: 352x640 4 persons, 126.1ms\n",
            "Speed: 2.8ms preprocess, 126.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0505.jpg: 352x640 4 persons, 126.4ms\n",
            "Speed: 2.8ms preprocess, 126.4ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0506.jpg: 352x640 4 persons, 127.8ms\n",
            "Speed: 2.8ms preprocess, 127.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0507.jpg: 352x640 4 persons, 123.8ms\n",
            "Speed: 2.8ms preprocess, 123.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0508.jpg: 352x640 4 persons, 124.4ms\n",
            "Speed: 2.9ms preprocess, 124.4ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0509.jpg: 352x640 4 persons, 125.5ms\n",
            "Speed: 2.9ms preprocess, 125.5ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0510.jpg: 352x640 4 persons, 136.0ms\n",
            "Speed: 3.9ms preprocess, 136.0ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0511.jpg: 352x640 4 persons, 137.0ms\n",
            "Speed: 2.8ms preprocess, 137.0ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0512.jpg: 352x640 4 persons, 124.1ms\n",
            "Speed: 2.9ms preprocess, 124.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0513.jpg: 352x640 4 persons, 124.2ms\n",
            "Speed: 2.8ms preprocess, 124.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0514.jpg: 352x640 4 persons, 124.6ms\n",
            "Speed: 2.8ms preprocess, 124.6ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0515.jpg: 352x640 4 persons, 125.5ms\n",
            "Speed: 2.8ms preprocess, 125.5ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0516.jpg: 352x640 3 persons, 139.0ms\n",
            "Speed: 3.9ms preprocess, 139.0ms inference, 1.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0517.jpg: 352x640 3 persons, 125.6ms\n",
            "Speed: 3.0ms preprocess, 125.6ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0518.jpg: 352x640 3 persons, 124.4ms\n",
            "Speed: 2.8ms preprocess, 124.4ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0519.jpg: 352x640 3 persons, 125.3ms\n",
            "Speed: 2.8ms preprocess, 125.3ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0520.jpg: 352x640 3 persons, 126.5ms\n",
            "Speed: 2.9ms preprocess, 126.5ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0521.jpg: 352x640 3 persons, 137.4ms\n",
            "Speed: 2.9ms preprocess, 137.4ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0522.jpg: 352x640 3 persons, 130.4ms\n",
            "Speed: 3.2ms preprocess, 130.4ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0523.jpg: 352x640 4 persons, 124.6ms\n",
            "Speed: 2.8ms preprocess, 124.6ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0524.jpg: 352x640 4 persons, 125.0ms\n",
            "Speed: 2.8ms preprocess, 125.0ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0525.jpg: 352x640 3 persons, 126.5ms\n",
            "Speed: 2.9ms preprocess, 126.5ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0526.jpg: 352x640 3 persons, 128.8ms\n",
            "Speed: 3.0ms preprocess, 128.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0527.jpg: 352x640 4 persons, 149.2ms\n",
            "Speed: 2.9ms preprocess, 149.2ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0528.jpg: 352x640 4 persons, 127.3ms\n",
            "Speed: 2.7ms preprocess, 127.3ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0529.jpg: 352x640 4 persons, 124.0ms\n",
            "Speed: 2.9ms preprocess, 124.0ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0530.jpg: 352x640 4 persons, 125.0ms\n",
            "Speed: 2.8ms preprocess, 125.0ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0531.jpg: 352x640 4 persons, 127.1ms\n",
            "Speed: 3.3ms preprocess, 127.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0532.jpg: 352x640 4 persons, 139.5ms\n",
            "Speed: 3.0ms preprocess, 139.5ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0533.jpg: 352x640 4 persons, 127.1ms\n",
            "Speed: 2.8ms preprocess, 127.1ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0534.jpg: 352x640 4 persons, 134.7ms\n",
            "Speed: 2.8ms preprocess, 134.7ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0535.jpg: 352x640 4 persons, 125.2ms\n",
            "Speed: 2.7ms preprocess, 125.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0536.jpg: 352x640 4 persons, 125.1ms\n",
            "Speed: 2.7ms preprocess, 125.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0537.jpg: 352x640 5 persons, 123.5ms\n",
            "Speed: 2.8ms preprocess, 123.5ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0538.jpg: 352x640 6 persons, 147.9ms\n",
            "Speed: 2.8ms preprocess, 147.9ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0539.jpg: 352x640 5 persons, 124.0ms\n",
            "Speed: 3.0ms preprocess, 124.0ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0540.jpg: 352x640 5 persons, 124.0ms\n",
            "Speed: 2.8ms preprocess, 124.0ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0541.jpg: 352x640 5 persons, 122.6ms\n",
            "Speed: 2.7ms preprocess, 122.6ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0542.jpg: 352x640 5 persons, 129.8ms\n",
            "Speed: 2.8ms preprocess, 129.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0543.jpg: 352x640 4 persons, 130.5ms\n",
            "Speed: 2.8ms preprocess, 130.5ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0544.jpg: 352x640 5 persons, 126.3ms\n",
            "Speed: 2.8ms preprocess, 126.3ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0545.jpg: 352x640 5 persons, 124.2ms\n",
            "Speed: 2.8ms preprocess, 124.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0546.jpg: 352x640 5 persons, 124.5ms\n",
            "Speed: 2.9ms preprocess, 124.5ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0547.jpg: 352x640 5 persons, 128.3ms\n",
            "Speed: 2.7ms preprocess, 128.3ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0548.jpg: 352x640 4 persons, 122.9ms\n",
            "Speed: 2.7ms preprocess, 122.9ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0549.jpg: 352x640 4 persons, 144.5ms\n",
            "Speed: 2.9ms preprocess, 144.5ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0550.jpg: 352x640 5 persons, 167.4ms\n",
            "Speed: 2.8ms preprocess, 167.4ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0551.jpg: 352x640 3 persons, 200.9ms\n",
            "Speed: 3.9ms preprocess, 200.9ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0552.jpg: 352x640 3 persons, 196.3ms\n",
            "Speed: 4.0ms preprocess, 196.3ms inference, 1.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0553.jpg: 352x640 3 persons, 213.2ms\n",
            "Speed: 4.2ms preprocess, 213.2ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0554.jpg: 352x640 3 persons, 193.2ms\n",
            "Speed: 4.0ms preprocess, 193.2ms inference, 1.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0555.jpg: 352x640 3 persons, 192.0ms\n",
            "Speed: 4.0ms preprocess, 192.0ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0556.jpg: 352x640 3 persons, 201.3ms\n",
            "Speed: 4.0ms preprocess, 201.3ms inference, 2.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0557.jpg: 352x640 3 persons, 221.4ms\n",
            "Speed: 4.1ms preprocess, 221.4ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0558.jpg: 352x640 3 persons, 196.8ms\n",
            "Speed: 4.2ms preprocess, 196.8ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0559.jpg: 352x640 4 persons, 199.2ms\n",
            "Speed: 3.9ms preprocess, 199.2ms inference, 1.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0560.jpg: 352x640 4 persons, 190.0ms\n",
            "Speed: 4.0ms preprocess, 190.0ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0561.jpg: 352x640 4 persons, 136.8ms\n",
            "Speed: 3.0ms preprocess, 136.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0562.jpg: 352x640 4 persons, 127.0ms\n",
            "Speed: 2.9ms preprocess, 127.0ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0563.jpg: 352x640 4 persons, 123.7ms\n",
            "Speed: 2.7ms preprocess, 123.7ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0564.jpg: 352x640 4 persons, 123.8ms\n",
            "Speed: 2.9ms preprocess, 123.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0565.jpg: 352x640 4 persons, 133.7ms\n",
            "Speed: 2.9ms preprocess, 133.7ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0566.jpg: 352x640 3 persons, 130.8ms\n",
            "Speed: 2.9ms preprocess, 130.8ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0567.jpg: 352x640 3 persons, 125.5ms\n",
            "Speed: 2.8ms preprocess, 125.5ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0568.jpg: 352x640 3 persons, 125.8ms\n",
            "Speed: 2.9ms preprocess, 125.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0569.jpg: 352x640 3 persons, 132.0ms\n",
            "Speed: 2.9ms preprocess, 132.0ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0570.jpg: 352x640 3 persons, 138.8ms\n",
            "Speed: 2.8ms preprocess, 138.8ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0571.jpg: 352x640 3 persons, 129.4ms\n",
            "Speed: 2.7ms preprocess, 129.4ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0572.jpg: 352x640 3 persons, 139.8ms\n",
            "Speed: 2.8ms preprocess, 139.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0573.jpg: 352x640 3 persons, 125.5ms\n",
            "Speed: 2.8ms preprocess, 125.5ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0574.jpg: 352x640 3 persons, 130.6ms\n",
            "Speed: 2.8ms preprocess, 130.6ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0575.jpg: 352x640 3 persons, 126.7ms\n",
            "Speed: 2.8ms preprocess, 126.7ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0576.jpg: 352x640 4 persons, 137.3ms\n",
            "Speed: 3.3ms preprocess, 137.3ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0577.jpg: 352x640 3 persons, 161.4ms\n",
            "Speed: 3.9ms preprocess, 161.4ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0578.jpg: 352x640 3 persons, 127.5ms\n",
            "Speed: 2.8ms preprocess, 127.5ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0579.jpg: 352x640 3 persons, 127.0ms\n",
            "Speed: 2.9ms preprocess, 127.0ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0580.jpg: 352x640 3 persons, 125.3ms\n",
            "Speed: 2.8ms preprocess, 125.3ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0581.jpg: 352x640 3 persons, 135.5ms\n",
            "Speed: 2.9ms preprocess, 135.5ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0582.jpg: 352x640 3 persons, 129.3ms\n",
            "Speed: 2.8ms preprocess, 129.3ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0583.jpg: 352x640 3 persons, 141.1ms\n",
            "Speed: 2.8ms preprocess, 141.1ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0584.jpg: 352x640 3 persons, 129.1ms\n",
            "Speed: 2.8ms preprocess, 129.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0585.jpg: 352x640 3 persons, 131.4ms\n",
            "Speed: 3.9ms preprocess, 131.4ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0586.jpg: 352x640 3 persons, 139.6ms\n",
            "Speed: 2.8ms preprocess, 139.6ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0587.jpg: 352x640 3 persons, 127.8ms\n",
            "Speed: 2.8ms preprocess, 127.8ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0588.jpg: 352x640 3 persons, 136.0ms\n",
            "Speed: 2.8ms preprocess, 136.0ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0589.jpg: 352x640 3 persons, 123.7ms\n",
            "Speed: 2.8ms preprocess, 123.7ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0590.jpg: 352x640 3 persons, 127.1ms\n",
            "Speed: 3.4ms preprocess, 127.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0591.jpg: 352x640 3 persons, 124.4ms\n",
            "Speed: 2.9ms preprocess, 124.4ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0592.jpg: 352x640 3 persons, 123.8ms\n",
            "Speed: 2.8ms preprocess, 123.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0593.jpg: 352x640 3 persons, 125.3ms\n",
            "Speed: 3.0ms preprocess, 125.3ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0594.jpg: 352x640 3 persons, 135.8ms\n",
            "Speed: 2.8ms preprocess, 135.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0595.jpg: 352x640 3 persons, 123.0ms\n",
            "Speed: 2.8ms preprocess, 123.0ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0596.jpg: 352x640 3 persons, 123.2ms\n",
            "Speed: 2.8ms preprocess, 123.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0597.jpg: 352x640 3 persons, 130.4ms\n",
            "Speed: 3.0ms preprocess, 130.4ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0598.jpg: 352x640 3 persons, 126.6ms\n",
            "Speed: 2.9ms preprocess, 126.6ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0599.jpg: 352x640 3 persons, 123.2ms\n",
            "Speed: 2.9ms preprocess, 123.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0600.jpg: 352x640 3 persons, 126.9ms\n",
            "Speed: 2.9ms preprocess, 126.9ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0601.jpg: 352x640 3 persons, 129.1ms\n",
            "Speed: 2.8ms preprocess, 129.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0602.jpg: 352x640 3 persons, 128.4ms\n",
            "Speed: 2.8ms preprocess, 128.4ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0603.jpg: 352x640 3 persons, 125.2ms\n",
            "Speed: 2.7ms preprocess, 125.2ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0604.jpg: 352x640 3 persons, 125.2ms\n",
            "Speed: 2.9ms preprocess, 125.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0605.jpg: 352x640 3 persons, 136.7ms\n",
            "Speed: 2.8ms preprocess, 136.7ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0606.jpg: 352x640 3 persons, 128.5ms\n",
            "Speed: 2.8ms preprocess, 128.5ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0607.jpg: 352x640 3 persons, 125.6ms\n",
            "Speed: 2.9ms preprocess, 125.6ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0608.jpg: 352x640 3 persons, 134.2ms\n",
            "Speed: 3.0ms preprocess, 134.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0609.jpg: 352x640 3 persons, 128.0ms\n",
            "Speed: 2.9ms preprocess, 128.0ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0610.jpg: 352x640 3 persons, 126.4ms\n",
            "Speed: 2.9ms preprocess, 126.4ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0611.jpg: 352x640 3 persons, 125.8ms\n",
            "Speed: 2.9ms preprocess, 125.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0612.jpg: 352x640 3 persons, 125.6ms\n",
            "Speed: 2.8ms preprocess, 125.6ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0613.jpg: 352x640 3 persons, 134.7ms\n",
            "Speed: 2.9ms preprocess, 134.7ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0614.jpg: 352x640 3 persons, 201.7ms\n",
            "Speed: 3.9ms preprocess, 201.7ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0615.jpg: 352x640 3 persons, 208.4ms\n",
            "Speed: 3.9ms preprocess, 208.4ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0616.jpg: 352x640 3 persons, 194.1ms\n",
            "Speed: 4.0ms preprocess, 194.1ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0617.jpg: 352x640 3 persons, 205.1ms\n",
            "Speed: 4.0ms preprocess, 205.1ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0618.jpg: 352x640 3 persons, 192.1ms\n",
            "Speed: 4.0ms preprocess, 192.1ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0619.jpg: 352x640 3 persons, 198.3ms\n",
            "Speed: 4.1ms preprocess, 198.3ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0620.jpg: 352x640 3 persons, 198.5ms\n",
            "Speed: 4.1ms preprocess, 198.5ms inference, 1.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0621.jpg: 352x640 3 persons, 196.0ms\n",
            "Speed: 4.3ms preprocess, 196.0ms inference, 2.7ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0622.jpg: 352x640 3 persons, 206.0ms\n",
            "Speed: 4.2ms preprocess, 206.0ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0623.jpg: 352x640 3 persons, 209.6ms\n",
            "Speed: 4.1ms preprocess, 209.6ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0624.jpg: 352x640 3 persons, 163.8ms\n",
            "Speed: 4.0ms preprocess, 163.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0625.jpg: 352x640 3 persons, 123.3ms\n",
            "Speed: 2.8ms preprocess, 123.3ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0626.jpg: 352x640 3 persons, 124.1ms\n",
            "Speed: 2.8ms preprocess, 124.1ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0627.jpg: 352x640 3 persons, 128.0ms\n",
            "Speed: 2.8ms preprocess, 128.0ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0628.jpg: 352x640 3 persons, 138.2ms\n",
            "Speed: 2.7ms preprocess, 138.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0629.jpg: 352x640 3 persons, 127.1ms\n",
            "Speed: 2.8ms preprocess, 127.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0630.jpg: 352x640 3 persons, 129.8ms\n",
            "Speed: 3.8ms preprocess, 129.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0631.jpg: 352x640 3 persons, 127.3ms\n",
            "Speed: 2.8ms preprocess, 127.3ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0632.jpg: 352x640 3 persons, 125.3ms\n",
            "Speed: 2.9ms preprocess, 125.3ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0633.jpg: 352x640 3 persons, 124.2ms\n",
            "Speed: 3.1ms preprocess, 124.2ms inference, 2.9ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0634.jpg: 352x640 3 persons, 128.3ms\n",
            "Speed: 4.0ms preprocess, 128.3ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0635.jpg: 352x640 3 persons, 133.9ms\n",
            "Speed: 3.7ms preprocess, 133.9ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0636.jpg: 352x640 3 persons, 129.3ms\n",
            "Speed: 2.9ms preprocess, 129.3ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0637.jpg: 352x640 3 persons, 126.1ms\n",
            "Speed: 2.8ms preprocess, 126.1ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0638.jpg: 352x640 3 persons, 124.1ms\n",
            "Speed: 2.9ms preprocess, 124.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0639.jpg: 352x640 4 persons, 138.7ms\n",
            "Speed: 2.8ms preprocess, 138.7ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0640.jpg: 352x640 6 persons, 132.0ms\n",
            "Speed: 2.8ms preprocess, 132.0ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/extracted_frames/frame_0641.jpg: 352x640 6 persons, 124.9ms\n",
            "Speed: 2.8ms preprocess, 124.9ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "✅ Object detection completed and saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Filtering Alerts Based on Confidence & Objects\n",
        "df_alerts = df_all[df_all[\"confidence\"] > 0.5]  # Filter by confidence threshold\n",
        "\n",
        "alert_classes = [\"person\", \"car\", \"drone\"]  # Define classes of interest\n",
        "df_alerts = df_alerts[df_alerts[\"name\"].isin(alert_classes)]\n",
        "\n",
        "df_alerts.to_csv(\"/content/alert_detections.csv\", index=False)\n",
        "print(f\"✅ {len(df_alerts)} alerts detected!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ty0hCAkBr2VB",
        "outputId": "97136c47-21bb-4319-d227-00dc0f0c93f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 1422 alerts detected!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Keeping only high-confidence alerts (e.g., confidence > 0.7)\n",
        "df_alerts = df_alerts[df_alerts[\"confidence\"] > 0.7]\n",
        "\n",
        "# If \"severity\" exists, filter by highest severity levels\n",
        "# df_alerts = df_alerts[df_alerts[\"severity\"] >= 2]\n"
      ],
      "metadata": {
        "id": "bwgMCUql10PK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_alerts = df_alerts.sort_values(by=\"frame\")  # Sort by frame number\n",
        "df_alerts = df_alerts.drop_duplicates(subset=[\"class\"], keep=\"first\")  # Keep only first detection of each object class in a frame\n"
      ],
      "metadata": {
        "id": "nVNrSMTH2DC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting Alert Clips from the Video\n",
        "\n",
        "import ffmpeg\n",
        "\n",
        "alert_clips_folder = \"/content/alert_clips\"\n",
        "os.makedirs(alert_clips_folder, exist_ok=True)\n",
        "\n",
        "for index, row in df_alerts.iterrows():\n",
        "    start_time = max(0, (row[\"frame\"] / fps) - 2)  # 2 seconds before detection\n",
        "    end_time = start_time + 5  # 5-second clip\n",
        "\n",
        "    clip_path = os.path.join(alert_clips_folder, f\"alert_clip_{index}.mp4\")\n",
        "\n",
        "    (\n",
        "        ffmpeg\n",
        "        .input(video_path, ss=start_time, to=end_time)\n",
        "        .output(clip_path, vcodec=\"libx264\", acodec=\"aac\")\n",
        "        .run(overwrite_output=True)\n",
        "    )\n",
        "\n",
        "    print(f\"✅ Extracted: {clip_path}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSW5oPzorGo3",
        "outputId": "81e23523-aa61-4437-e38d-2b48180596db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Extracted: /content/alert_clips/alert_clip_0.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify Clips & Playback\n",
        "import glob\n",
        "\n",
        "clips = glob.glob(\"/content/alert_clips/*.mp4\")\n",
        "if clips:\n",
        "    print(f\"✅ {len(clips)} alert clips generated!\")\n",
        "else:\n",
        "    print(\"❌ No clips were generated. Check detection results.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVhpjxahs3hd",
        "outputId": "e55d5b66-6bad-44f7-9d56-24fa9404ca70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 29 alert clips generated!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a Text File Listing the Clips\n",
        "import os\n",
        "\n",
        "clips_folder = \"/content/alert_clips\"\n",
        "clip_files = sorted([f for f in os.listdir(clips_folder) if f.endswith(\".mp4\")])\n",
        "\n",
        "# Ensure clips are found\n",
        "if not clip_files:\n",
        "    print(\"No clips found!\")\n",
        "else:\n",
        "    # Create a file list for ffmpeg\n",
        "    with open(\"file_list.txt\", \"w\") as f:\n",
        "        for clip in clip_files:\n",
        "            f.write(f\"file '{clips_folder}/{clip}'\\n\")\n",
        "\n",
        "    print(\"File list created successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Kpkmn6es_kd",
        "outputId": "2fd6fef1-c331-4209-8112-651dcb8bedcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File list created successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ffmpeg -f concat -safe 0 -i /content/alert_clips.txt -c copy /content/alert_clips/merged_alert_clips.mp4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TX3ZC-j7mYT",
        "outputId": "dd1b0e18-c703-4537-fd2d-0a4ad58eea1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "\u001b[1;31m/content/alert_clips.txt: No such file or directory\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls -lh /content/alert_clips/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T40pdMlB74qz",
        "outputId": "5796153e-132b-4060-ca84-0ee9417ceeee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 274M\n",
            "-rw-r--r-- 1 root root 9.8M Mar 31 06:20 alert_clip_0.mp4\n",
            "-rw-r--r-- 1 root root 9.8M Mar 31 05:47 alert_clip_10.mp4\n",
            "-rw-r--r-- 1 root root 9.8M Mar 31 05:48 alert_clip_12.mp4\n",
            "-rw-r--r-- 1 root root 9.8M Mar 31 05:50 alert_clip_13.mp4\n",
            "-rw-r--r-- 1 root root 9.8M Mar 31 05:51 alert_clip_15.mp4\n",
            "-rw-r--r-- 1 root root 9.8M Mar 31 05:53 alert_clip_16.mp4\n",
            "-rw-r--r-- 1 root root 9.8M Mar 31 05:54 alert_clip_18.mp4\n",
            "-rw-r--r-- 1 root root 9.8M Mar 31 05:56 alert_clip_19.mp4\n",
            "-rw-r--r-- 1 root root 9.8M Mar 31 05:39 alert_clip_1.mp4\n",
            "-rw-r--r-- 1 root root 9.8M Mar 31 05:57 alert_clip_21.mp4\n",
            "-rw-r--r-- 1 root root 9.8M Mar 31 05:58 alert_clip_22.mp4\n",
            "-rw-r--r-- 1 root root 9.8M Mar 31 06:00 alert_clip_24.mp4\n",
            "-rw-r--r-- 1 root root 9.8M Mar 31 06:01 alert_clip_25.mp4\n",
            "-rw-r--r-- 1 root root 9.8M Mar 31 06:03 alert_clip_27.mp4\n",
            "-rw-r--r-- 1 root root 9.8M Mar 31 06:04 alert_clip_28.mp4\n",
            "-rw-r--r-- 1 root root 9.8M Mar 31 06:05 alert_clip_30.mp4\n",
            "-rw-r--r-- 1 root root 9.8M Mar 31 06:07 alert_clip_31.mp4\n",
            "-rw-r--r-- 1 root root 9.8M Mar 31 06:08 alert_clip_33.mp4\n",
            "-rw-r--r-- 1 root root 9.8M Mar 31 06:10 alert_clip_34.mp4\n",
            "-rw-r--r-- 1 root root 9.8M Mar 31 06:11 alert_clip_36.mp4\n",
            "-rw-r--r-- 1 root root 9.8M Mar 31 06:12 alert_clip_37.mp4\n",
            "-rw-r--r-- 1 root root 9.8M Mar 31 06:14 alert_clip_39.mp4\n",
            "-rw-r--r-- 1 root root 9.8M Mar 31 05:40 alert_clip_3.mp4\n",
            "-rw-r--r-- 1 root root 9.8M Mar 31 06:15 alert_clip_40.mp4\n",
            "-rw-r--r-- 1 root root 1.1M Mar 31 06:15 alert_clip_41.mp4\n",
            "-rw-r--r-- 1 root root 9.8M Mar 31 05:41 alert_clip_4.mp4\n",
            "-rw-r--r-- 1 root root 9.8M Mar 31 05:43 alert_clip_6.mp4\n",
            "-rw-r--r-- 1 root root 9.8M Mar 31 05:44 alert_clip_7.mp4\n",
            "-rw-r--r-- 1 root root 9.8M Mar 31 05:46 alert_clip_9.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/alert_clips/ && ls -1 *.mp4 | sed \"s/^/file '/;s/$/'/\" > /content/alert_clips.txt\n"
      ],
      "metadata": {
        "id": "Pc0HWtu_8BYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat /content/alert_clips.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45nk_4nU8UUL",
        "outputId": "669c3879-64d0-4afe-862d-866dadfe73ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file 'alert_clip_0.mp4'\n",
            "file 'alert_clip_10.mp4'\n",
            "file 'alert_clip_12.mp4'\n",
            "file 'alert_clip_13.mp4'\n",
            "file 'alert_clip_15.mp4'\n",
            "file 'alert_clip_16.mp4'\n",
            "file 'alert_clip_18.mp4'\n",
            "file 'alert_clip_19.mp4'\n",
            "file 'alert_clip_1.mp4'\n",
            "file 'alert_clip_21.mp4'\n",
            "file 'alert_clip_22.mp4'\n",
            "file 'alert_clip_24.mp4'\n",
            "file 'alert_clip_25.mp4'\n",
            "file 'alert_clip_27.mp4'\n",
            "file 'alert_clip_28.mp4'\n",
            "file 'alert_clip_30.mp4'\n",
            "file 'alert_clip_31.mp4'\n",
            "file 'alert_clip_33.mp4'\n",
            "file 'alert_clip_34.mp4'\n",
            "file 'alert_clip_36.mp4'\n",
            "file 'alert_clip_37.mp4'\n",
            "file 'alert_clip_39.mp4'\n",
            "file 'alert_clip_3.mp4'\n",
            "file 'alert_clip_40.mp4'\n",
            "file 'alert_clip_41.mp4'\n",
            "file 'alert_clip_4.mp4'\n",
            "file 'alert_clip_6.mp4'\n",
            "file 'alert_clip_7.mp4'\n",
            "file 'alert_clip_9.mp4'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/alert_clips/ && ls -1 *.mp4 | sed \"s|^|file '/content/alert_clips/|;s|$|'|\" > /content/alert_clips.txt\n"
      ],
      "metadata": {
        "id": "08KYwJ2w8Wte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ffmpeg -f concat -safe 0 -i /content/alert_clips.txt -c copy /content/alert_clips/merged_alert_clips.mp4\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5SGxqjN8nfC",
        "outputId": "09747cd5-a4fc-4bde-a2f3-eea6571c7d76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "\u001b[0;35m[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5d2c13789dc0] \u001b[0mAuto-inserting h264_mp4toannexb bitstream filter\n",
            "Input #0, concat, from '/content/alert_clips.txt':\n",
            "  Duration: N/A, start: -0.021333, bitrate: 16308 kb/s\n",
            "  Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709), 4096x2160 [SAR 1:1 DAR 256:135], 16305 kb/s, 23.98 fps, 23.98 tbr, 24k tbn, 47.95 tbc\n",
            "    Metadata:\n",
            "      handler_name    : L-SMASH Video Handler\n",
            "      vendor_id       : [0][0][0][0]\n",
            "  Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, stereo, fltp, 2 kb/s\n",
            "    Metadata:\n",
            "      handler_name    : L-SMASH Audio Handler\n",
            "      vendor_id       : [0][0][0][0]\n",
            "File '/content/alert_clips/merged_alert_clips.mp4' already exists. Overwrite? [y/N] ^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls -lh /content/alert_clips/merged_alert_clips.mp4\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IC1fzlsc8zuB",
        "outputId": "d5fec231-223a-4dd5-abb8-1ced9d145eda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 234M Mar 31 06:45 /content/alert_clips/merged_alert_clips.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Video\n",
        "\n",
        "video_path = \"/content/alert_clips/merged_alert_clips.mp4\"\n",
        "display(Video(video_path, embed=True))\n",
        "\n"
      ],
      "metadata": {
        "id": "zUYyf71u83KR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#saving video to local system\n",
        "from google.colab import files\n",
        "files.download(\"/content/alert_clips/merged_alert_clips.mp4\")\n"
      ],
      "metadata": {
        "id": "aIbEB83_9R2K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}